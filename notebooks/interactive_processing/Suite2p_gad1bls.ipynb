{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from suite2p import run_s2p\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tables\n",
    "import shutil\n",
    "# import flammkuchen as fl\n",
    "from tqdm import tqdm\n",
    "import hdfplugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_path =  Path(r\"\\\\FUNES\\Shared\\experiments\\E0040_motions_cardinal\\batch210922\")\n",
    "# master_path = Path(r\"\\\\FUNES\\Shared\\experiments\\E0040_motions_cardinal\\v15_playback\")\n",
    "files = list(master_path.glob(\"*_f*\"))\n",
    "print(files)\n",
    "\n",
    "fast_path_dest =  Path(r\"C:\\Users\\lpetrucco\\temp_suite2p\")\n",
    "\n",
    "unprocessed = [f for f in files if not (f / \"suite2p\" / \"combined\").exists()]\n",
    "unprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in tqdm(unprocessed):\n",
    "    print(\"#####################################\")\n",
    "    print(path)\n",
    "    dataset_path = path / \"original\"\n",
    "    \n",
    "    fast_path = fast_path_dest\n",
    "    fast_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        with open(next(path.glob(\"*metadata.json\"))) as f:\n",
    "             metadata = json.load(f)\n",
    "        fs = int(metadata[\"imaging\"][\"microscope_config\"][\"lightsheet\"][\"scanning\"][\"z\"][\"frequency\"]) # sampling frequency\n",
    "    except:\n",
    "        fs = 5\n",
    "\n",
    "    with open(dataset_path / \"stack_metadata.json\") as f:\n",
    "        stack_metadata = json.load(f)\n",
    "        \n",
    "    n_planes = stack_metadata[\"shape_full\"][1]  # number of planes\n",
    "    \n",
    "    ops = {\n",
    "        # file paths\n",
    "        'look_one_level_down': False, # whether to look in all subfolders when searching for tiffs\n",
    "        'fast_disk': str(fast_path), # used to store temporary binary file, defaults to save_path0\n",
    "        'delete_bin': False, # whether to delete binary file after processing\n",
    "        'mesoscan': False, # for reading in scanimage mesoscope files\n",
    "        'bruker': False, # whether or not single page BRUKER tiffs!\n",
    "        'h5py': str(dataset_path), # take h5py as input (deactivates data_path)\n",
    "        'h5py_key': 'stack_4D', #key in h5py where data array is stored\n",
    "        'save_path0': [], # stores results, defaults to first item in data_path\n",
    "        'save_folder': [],\n",
    "        'subfolders': [],\n",
    "        'move_bin': True, # if 1, and fast_disk is different than save_disk, binary file is moved to save_disk\n",
    "        \n",
    "        # main settings\n",
    "        'nplanes' : n_planes, # each tiff has these many planes in sequence\n",
    "        'nchannels' : 1, # each tiff has these many channels per plane\n",
    "        'functional_chan' : 1, # this channel is used to extract functional ROIs (1-based)\n",
    "        'tau':  1., # this is the main parameter for deconvolution\n",
    "        'fs': fs,  # sampling rate (PER PLANE e.g. for 12 plane recordings it will be around 2.5)\n",
    "        'force_sktiff': False, # whether or not to use scikit-image for tiff reading\n",
    "        'frames_include': -1,\n",
    "        \"num_workers\": 10,\n",
    "        \n",
    "        # output settings\n",
    "        'preclassify': 0., # apply classifier before signal extraction with probability 0.3\n",
    "        'save_mat': False, # whether to save output as matlab files\n",
    "        'combined': True, # combine multiple planes into a single result /single canvas for GUI\n",
    "        'aspect': 1.0, # um/pixels in X / um/pixels in Y (for correct aspect ratio in GUI)\n",
    "        \n",
    "        # bidirectional phase offset\n",
    "        'do_bidiphase': False,\n",
    "        'bidiphase': 0,\n",
    "        'bidi_corrected': False,\n",
    "        \n",
    "        # registration settings\n",
    "        'do_registration': 1, # whether to register data (2 forces re-registration)\n",
    "        'two_step_registration': False,\n",
    "        'keep_movie_raw': False,\n",
    "        'nimg_init': 300, # subsampled frames for finding reference image\n",
    "        'batch_size': 500, # number of frames per batch\n",
    "        'maxregshift': 0.1, # max allowed registration shift, as a fraction of frame max(width and height)\n",
    "        'align_by_chan' : 1, # when multi-channel, you can align by non-functional channel (1-based)\n",
    "        'reg_tif': False, # whether to save registered tiffs\n",
    "        'reg_tif_chan2': False, # whether to save channel 2 registered tiffs\n",
    "        'subpixel' : 5, # precision of subpixel registration (1/subpixel steps)\n",
    "        'smooth_sigma_time' : 0, # gaussian smoothing in time\n",
    "        'smooth_sigma': 1.15, # ~1 good for 2P recordings, recommend >5 for 1P recordings\n",
    "        'th_badframes': 1.0, # this parameter determines which frames to exclude when determining cropping - set it smaller to exclude more frames\n",
    "        'pad_fft': False,\n",
    "        \n",
    "        # non rigid registration settings\n",
    "        'nonrigid': True, # whether to use nonrigid registration\n",
    "        'block_size': [128, 128], # block size to register (** keep this a multiple of 2 **)\n",
    "        'snr_thresh': 1.2, # if any nonrigid block is below this threshold, it gets smoothed until above this threshold. 1.0 results in no smoothing\n",
    "        'maxregshiftNR': 5, # maximum pixel shift allowed for nonrigid, relative to rigid\n",
    "        \n",
    "         # 1P settings\n",
    "        '1Preg': False, # whether to perform high-pass filtering and tapering\n",
    "        'spatial_hp': 25, # window for spatial high-pass filtering before registration\n",
    "        'pre_smooth': 2, # whether to smooth before high-pass filtering before registration\n",
    "        'spatial_taper': 50, # how much to ignore on edges (important for vignetted windows, for FFT padding do not set BELOW 3*ops['smooth_sigma'])\n",
    "        \n",
    "        # cell detection settings\n",
    "        'roidetect': True, # whether or not to run ROI extraction\n",
    "        'sparse_mode': True, # whether or not to run sparse_mode\n",
    "        'diameter': 6, # if not sparse_mode, use diameter for filtering and extracting\n",
    "        'spatial_scale': 0, # 0: multi-scale; 1: 6 pixels, 2: 12 pixels, 3: 24 pixels, 4: 48 pixels\n",
    "        'connected': True, # whether or not to keep ROIs fully connected (set to 0 for dendrites)\n",
    "        'nbinned': 5000, # max number of binned frames for cell detection\n",
    "        'max_iterations': 20, # maximum number of iterations to do cell detection\n",
    "        'threshold_scaling': 1.4\n",
    "        , # adjust the automatically determined threshold by this scalar multiplier\n",
    "        'max_overlap': 0.99, # cells with more overlap than this get removed during triage, before refinement\n",
    "        'high_pass': 100, # running mean subtraction with window of size 'high_pass' (use low values for 1P)\n",
    "        \n",
    "        # ROI extraction parameters\n",
    "        'inner_neuropil_radius': 2, # number of pixels to keep between ROI and neuropil donut\n",
    "        'min_neuropil_pixels': 350, # minimum number of pixels in the neuropil\n",
    "        'allow_overlap': False, # pixels that are overlapping are thrown out (False) or added to both ROIs (True)\n",
    "    \n",
    "        # channel 2 detection settings (stat[n]['chan2'], stat[n]['not_chan2'])\n",
    "        'chan2_thres': 0.65, # minimum for detection of brightness on channel 2\n",
    "    \n",
    "        # deconvolution settings\n",
    "        'spikedetect': False, # whether or not to run spike deconvolution\n",
    "        'baseline': 'maximin', # baselining mode (can also choose 'prctile')\n",
    "        'win_baseline': 60., # window for maximin\n",
    "        'sig_baseline': 10., # smoothing constant for gaussian filter\n",
    "        'prctile_baseline': 8.,# optional (whether to use a percentile baseline)\n",
    "        'neucoeff': .7,  # neuropil coefficient\n",
    "        'xrange': np.array([0, 0]),\n",
    "        'yrange': np.array([0, 0]),\n",
    "    }\n",
    "    \n",
    "    db = {'data_path': [str(dataset_path)]}\n",
    "    \n",
    "    try:\n",
    "        opsEnd=run_s2p(ops=ops, db=db)\n",
    "    except (UnboundLocalError, ValueError):\n",
    "        print(\"Error for fish \", path)\n",
    "    \n",
    "    shutil.rmtree(fast_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
