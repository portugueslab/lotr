{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78f1dd18-5a7d-4374-9692-9b282b15373c",
   "metadata": {},
   "source": [
    "# The aHB circuit tracks fictive trajectories\n",
    "\n",
    "We have seen in the previous notebooks that the aHB integrator could be capabable of keep track of past motion over a significant amount of time. In this notebook, we will see how much it can keep track of past trajectories over significant amounts of time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60c0332-0fac-4b62-b727-7ca37821764c",
   "metadata": {},
   "source": [
    "## A first look at cumulative directional motion and network phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a90407e-47d8-464b-9841-6a347d248513",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from pathlib import Path\n",
    "\n",
    "import lotr.plotting as pltltr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bouter.utilities import crop\n",
    "from lotr import A_FISH, LotrExperiment, dataset_folders\n",
    "from lotr.behavior import get_bouts_props_array\n",
    "from lotr.default_vals import REGRESSOR_TAU_S\n",
    "from lotr.utils import convolve_with_tau\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from tqdm import tqdm\n",
    "\n",
    "COLS = pltltr.COLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c79182-f95c-4cb0-8332-14b889e0b176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, get the unwrapped phase:\n",
    "exp = LotrExperiment(A_FISH)\n",
    "network_phase = np.unwrap(exp.network_phase)\n",
    "\n",
    "# Now, let's find a way of reconstruct past motion of the fish.\n",
    "# We will start with a vector of zeros that has ones at timepoints\n",
    "# where the fish swam:\n",
    "theta_turned = get_bouts_props_array(\n",
    "    exp.n_pts, exp.bouts_df, selection=\"all\", value=\"bias\"\n",
    ")\n",
    "\n",
    "# Fictive heading will be the cumulative sum of this array:\n",
    "fictive_head = np.cumsum(theta_turned)\n",
    "\n",
    "# Finally, we smooth this array with a kernel that matches the slower dynamics\n",
    "# of the neuron (results are not much affected by this)\n",
    "fictive_head = convolve_with_tau(np.cumsum(theta_turned), REGRESSOR_TAU_S * exp.fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0992f0bf-e11b-4946-95f1-feb672613ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(\n",
    "    3, 1, figsize=(5, 3), sharex=True, gridspec_kw=(dict(bottom=0.12))\n",
    ")\n",
    "lw = 1\n",
    "\n",
    "labels = [\"Tail angle\", \"Angle turned (dθ)\", \"Fict. heading (θ)\"]\n",
    "col_seq = [COLS[\"beh\"], pltltr.shift_lum(COLS[\"th_plot\"], 0.2), COLS[\"th_plot\"]]\n",
    "for i, (x, y) in enumerate(\n",
    "    [\n",
    "        (exp.behavior_log[\"t\"], exp.behavior_log[\"tail_sum\"]),\n",
    "        (exp.time_arr, theta_turned),\n",
    "        (exp.time_arr, fictive_head),\n",
    "    ]\n",
    "):\n",
    "    axs[i].plot(\n",
    "        x, y, lw=lw, c=col_seq[i], label=labels[i], rasterized=i == 0\n",
    "    )  # rasterize for exporting\n",
    "    axs[i].legend(loc=1, bbox_to_anchor=(1.1, 1.1))\n",
    "\n",
    "axs[0].set(**pltltr.get_pi_labels(1, ax=\"y\"))\n",
    "axs[1].set(**pltltr.get_pi_labels(0.5, ax=\"y\"), ylim=(-1.8, 1.8))\n",
    "axs[2].set(xlabel=\"Time (s)\", **pltltr.get_pi_labels(coefs=(0, -5, -10, -15), ax=\"y\"))\n",
    "\n",
    "[pltltr.despine(ax) for ax in axs.flatten()]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6d99ab-c3fa-4bf2-bbd4-19750788c71d",
   "metadata": {},
   "source": [
    "Now, how does the network phase look, compared with the fictive heading?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3421e7ac-fe86-4bc8-ad51-0d02cb16f4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(\n",
    "    1, 1, figsize=(4, 1.5), gridspec_kw=(dict(bottom=0.25, right=0.85))\n",
    ")\n",
    "twin_ax = ax.twinx()\n",
    "ax.plot(\n",
    "    exp.time_arr, fictive_head, c=COLS[\"th_plot\"],\n",
    ")\n",
    "twin_ax.plot(\n",
    "    exp.time_arr, np.unwrap(exp.network_phase), c=COLS[\"ph_plot\"],\n",
    ")\n",
    "ax.set_ylabel(\"Fict. heading (θ)\", c=COLS[\"th_plot\"])\n",
    "ax.set(xlabel=\"Times (s)\", **pltltr.get_pi_labels(coefs=(0, -5, -10, -15), ax=\"y\"))\n",
    "twin_ax.set_ylabel(\"Network phase (ϕ)\", c=COLS[\"ph_plot\"])\n",
    "twin_ax.set(\n",
    "    ylim=twin_ax.get_ylim()[::-1], **pltltr.get_pi_labels(coefs=(0, 2, 4, 6), ax=\"y\")\n",
    ")\n",
    "rho, pval = spearmanr(fictive_head, np.unwrap(exp.network_phase))\n",
    "ax.text(1200, -np.pi, \"$ρ_r=\" + f\"{rho:0.3f}\" + \"$\" + pltltr.get_pval_stars(pval))\n",
    "[pltltr.despine(a, [\"top\"]) for a in [ax, twin_ax]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad44fe5-6b26-4bcf-89db-cf5ea30af9cd",
   "metadata": {},
   "source": [
    "## Quantify correlation over the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8c26f3-2f17-4ff1-9075-add4caff873b",
   "metadata": {},
   "outputs": [],
   "source": [
    "maybe = [\n",
    "    f.parent\n",
    "    for f in Path(r\"/Users/luigipetrucco/Desktop/all_source_data/maybe_ring\").glob(\n",
    "        \"*/*/selected.h5\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75af3989-4ed5-4398-a92a-7b0cac767e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORR_WND_S = 300\n",
    "N_OVERLAPS = 10\n",
    "MIN_BOUTS = 3\n",
    "\n",
    "# all_rho_vals = []\n",
    "# sh\n",
    "# all_fish_ps = []\n",
    "results_df = []\n",
    "for path in tqdm(dataset_folders):\n",
    "    # for path in tqdm(maybe):\n",
    "    exp = LotrExperiment(path)\n",
    "    phase = np.unwrap(exp.network_phase)\n",
    "    theta_turned = get_bouts_props_array(\n",
    "        exp.n_pts, exp.bouts_df, selection=\"all\", value=\"bias\"\n",
    "    )\n",
    "\n",
    "    # Fictive heading will be the cumulative sum of this array:\n",
    "    fictive_head = np.cumsum(theta_turned)\n",
    "    wnd_pts = int(CORR_WND_S * exp.fn)\n",
    "    overlap_pts = wnd_pts // N_OVERLAPS\n",
    "\n",
    "    # delta_moved = np.array([])\n",
    "    # all_rhos = np.array([])\n",
    "    # all_prs = np.array([])\n",
    "    # all_ps = np.array([])\n",
    "    # all_idxs =\n",
    "    # for i in range(wnd_pts, len(phase) - wnd_pts, overlap_pts):\n",
    "    #     wnd = slice(i, i + wnd_pts)\n",
    "    #     if np.sum(np.abs(theta_turned[wnd])) > MIN_BOUTS:\n",
    "\n",
    "    #         rho, p = spearmanr(phase[wnd], fictive_head[wnd])\n",
    "    #        r, p = pearsonr(phase[wnd], fictive_head[wnd])\n",
    "    #        all_rhos = np.append(all_rhos, rho)\n",
    "    #        all_ps = np.append(all_ps, p)\n",
    "    #    else:\n",
    "    #        all_rhos = np.append(all_rhos, np.nan)\n",
    "    # delta_moved = np.append(delta_moved, np.sum(np.abs(np.diff(heading[wnd]))))\n",
    "\n",
    "    indexes = list(range(0, len(phase) - wnd_pts, overlap_pts))\n",
    "    valid_indexes = []\n",
    "    for i in indexes:\n",
    "        if np.sum(np.abs(theta_turned[i : i + wnd_pts])) > MIN_BOUTS:\n",
    "            valid_indexes.append(i)\n",
    "\n",
    "    shuf_indexes = []\n",
    "    for i in valid_indexes:\n",
    "        shuf_i = i\n",
    "        c = 0\n",
    "        while np.abs(i - shuf_i) < wnd_pts // 2:\n",
    "            shuf_i = np.random.choice(valid_indexes)\n",
    "            c += 1\n",
    "            if c > 50:\n",
    "                print(\"could not find a valid shuffle for \", path.name)\n",
    "                break\n",
    "\n",
    "        shuf_indexes.append(shuf_i)\n",
    "\n",
    "    for i, shuf_i in zip(valid_indexes, shuf_indexes):\n",
    "        wnd = slice(i, i + wnd_pts)\n",
    "        shuf_wnd = slice(shuf_i, shuf_i + wnd_pts)\n",
    "        rho, p = spearmanr(phase[wnd], fictive_head[wnd])\n",
    "        rho_shuf, p_shuf = spearmanr(phase[wnd], fictive_head[shuf_wnd])\n",
    "\n",
    "        results_df.append(\n",
    "            dict(rho=rho, p=p, rho_shuf=rho_shuf, p_shuf=p_shuf, fid=exp.dir_name)\n",
    "        )\n",
    "\n",
    "    # all_rho_vals.append(all_rhos)\n",
    "    # all_fish_ps.append(all_ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8af62e-4042-4af1-8ece-85181ff56602",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44861564-3af3-453a-bc1e-3a48c58df60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = res_df.groupby(\"fid\").quantile((0.25, 0.50, 0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a314357-c571-4a4a-89cd-5720858d6a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos = np.array([np.nanpercentile(rhos, (25, 50, 75)) for rhos in all_rho_vals])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(rhos[np.argsort(rhos[:, 1]), :], c=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ea2861-9e58-4b95-9bf2-82e1acca4ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(all_vals[np.argsort(all_vals[:, 1]), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca2f5b6-aa34-4fa6-87f9-bc4d74bbfb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(all_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670f774b-8542-4fc6-a022-7707a6f207d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a070bb18-3875-42e3-96e6-ba9398984084",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist([r.correlation for r in rhos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c8e1b6-b5c9-43b9-9a16-5525857a1ece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2a641c-10a2-456d-b989-4778c6a2b5d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85d8bc0-e8b5-430a-8a08-19c73f1252e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63962a69-841b-4e7a-a1c6-004b4522829e",
   "metadata": {},
   "source": [
    "To run the correlation over the entire dataset, we will not use the whole trace to avoid the problem that a s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rplab",
   "language": "python",
   "name": "rplab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
