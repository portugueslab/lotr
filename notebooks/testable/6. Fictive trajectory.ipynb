{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78f1dd18-5a7d-4374-9692-9b282b15373c",
   "metadata": {},
   "source": [
    "# The aHB circuit tracks fictive trajectories\n",
    "\n",
    "We have seen in the previous notebooks that the aHB integrator could be capabable of keep track of past motion over a significant amount of time. In this notebook, we will see how much it can keep track of past trajectories over significant amounts of time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60c0332-0fac-4b62-b727-7ca37821764c",
   "metadata": {},
   "source": [
    "## A first look at cumulative directional motion and network phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a90407e-47d8-464b-9841-6a347d248513",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from pathlib import Path\n",
    "\n",
    "import lotr.plotting as pltltr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bouter.utilities import crop\n",
    "from lotr import A_FISH, LotrExperiment, dataset_folders\n",
    "from lotr.behavior import get_bouts_props_array\n",
    "from lotr.default_vals import REGRESSOR_TAU_S\n",
    "from lotr.utils import convolve_with_tau\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import spearmanr, wilcoxon\n",
    "from tqdm import tqdm\n",
    "\n",
    "COLS = pltltr.COLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c79182-f95c-4cb0-8332-14b889e0b176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, get the unwrapped phase:\n",
    "exp = LotrExperiment(A_FISH)\n",
    "network_phase = np.unwrap(exp.network_phase)\n",
    "\n",
    "# Now, let's find a way of reconstruct past motion of the fish.\n",
    "# We will start with a vector of zeros that has ones at timepoints\n",
    "# where the fish swam:\n",
    "theta_turned = get_bouts_props_array(\n",
    "    exp.n_pts, exp.bouts_df, selection=\"all\", value=\"bias\",\n",
    ")\n",
    "\n",
    "# Fictive heading will be the cumulative sum of this array:\n",
    "fictive_head = np.cumsum(theta_turned)\n",
    "\n",
    "# Finally, we smooth this array with a kernel that matches the slower dynamics\n",
    "# of the neuron (results are not much affected by this)\n",
    "fictive_head = convolve_with_tau(np.cumsum(theta_turned), REGRESSOR_TAU_S * exp.fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0992f0bf-e11b-4946-95f1-feb672613ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(\n",
    "    3, 1, figsize=(5, 3), sharex=True, gridspec_kw=(dict(bottom=0.12))\n",
    ")\n",
    "lw = 1\n",
    "\n",
    "labels = [\"Tail angle\", \"Angle turned (dθ)\", \"Fict. heading (θ)\"]\n",
    "col_seq = [COLS[\"beh\"], pltltr.shift_lum(COLS[\"th_plot\"], 0.2), COLS[\"th_plot\"]]\n",
    "for i, (x, y) in enumerate(\n",
    "    [\n",
    "        (exp.behavior_log[\"t\"], exp.behavior_log[\"tail_sum\"]),\n",
    "        (exp.time_arr, theta_turned),\n",
    "        (exp.time_arr, fictive_head),\n",
    "    ]\n",
    "):\n",
    "    axs[i].plot(\n",
    "        x, y, lw=lw, c=col_seq[i], label=labels[i], rasterized=i == 0\n",
    "    )  # rasterize for exporting\n",
    "    axs[i].legend(loc=1, bbox_to_anchor=(1.1, 1.1))\n",
    "\n",
    "axs[0].set(**pltltr.get_pi_labels(1, ax=\"y\"))\n",
    "axs[1].set(**pltltr.get_pi_labels(0.5, ax=\"y\"), ylim=(-1.8, 1.8))\n",
    "axs[2].set(xlabel=\"Time (s)\", **pltltr.get_pi_labels(coefs=(0, -5, -10, -15), ax=\"y\"))\n",
    "\n",
    "[pltltr.despine(ax) for ax in axs.flatten()]\n",
    "plt.show()\n",
    "pltltr.savefig(\"fictive_traj_computation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6d99ab-c3fa-4bf2-bbd4-19750788c71d",
   "metadata": {},
   "source": [
    "Now, how does the network phase look, compared with the fictive heading?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3421e7ac-fe86-4bc8-ad51-0d02cb16f4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(\n",
    "    1, 1, figsize=(4, 1.5), gridspec_kw=(dict(bottom=0.25, right=0.85))\n",
    ")\n",
    "twin_ax = ax.twinx()\n",
    "ax.plot(\n",
    "    exp.time_arr, fictive_head, c=COLS[\"th_plot\"],\n",
    ")\n",
    "twin_ax.plot(\n",
    "    exp.time_arr, np.unwrap(exp.network_phase), c=COLS[\"ph_plot\"],\n",
    ")\n",
    "ax.set_ylabel(\"Fict. heading (θ)\", c=COLS[\"th_plot\"])\n",
    "ax.set(xlabel=\"Times (s)\", **pltltr.get_pi_labels(coefs=(0, -5, -10, -15), ax=\"y\"))\n",
    "twin_ax.set_ylabel(\"Network phase (ϕ)\", c=COLS[\"ph_plot\"])\n",
    "twin_ax.set(\n",
    "    ylim=twin_ax.get_ylim()[::-1], **pltltr.get_pi_labels(coefs=(0, 2, 4, 6), ax=\"y\")\n",
    ")\n",
    "# rho, pval = spearmanr(fictive_head, np.unwrap(exp.network_phase))\n",
    "# ax.text(1200, -np.pi, \"$ρ_r=\" + f\"{rho:0.3f}\" + \"$\" + pltltr.get_pval_stars(pval))\n",
    "[pltltr.despine(a, [\"top\"]) for a in [ax, twin_ax]]\n",
    "\n",
    "pltltr.savefig(\"fictive_traj_phase_onefish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad44fe5-6b26-4bcf-89db-cf5ea30af9cd",
   "metadata": {},
   "source": [
    "## Quantify correlation over the entire dataset\n",
    "\n",
    "To run the correlation over the entire dataset, we will not use the whole trace to avoid the problem that a large drift at some point of the experiment could disrupt the correlation for the rest of it. Instead, we will use correlation in windows of 5 minutes, including only times where there were at least 2 directional bouts happening (otherwise fictive heading will be a flat line, with which correlation ill-defined)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75af3989-4ed5-4398-a92a-7b0cac767e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORR_WND_S = 300  # window over which correlation will be computed\n",
    "N_OVERLAPS = 10  # number of overlaps per window\n",
    "MIN_BOUTS = 2  # minimum number of bouts to inclide in the window\n",
    "\n",
    "results_df = []\n",
    "for path in tqdm(dataset_folders):\n",
    "    # for path in tqdm(maybe):\n",
    "    exp = LotrExperiment(path)\n",
    "    phase = np.unwrap(exp.network_phase)\n",
    "    theta_turned = get_bouts_props_array(\n",
    "        exp.n_pts, exp.bouts_df, selection=\"all\", value=\"bias\",\n",
    "    )\n",
    "\n",
    "    # Fictive heading will be the cumulative sum of this array:\n",
    "    fictive_head = np.cumsum(theta_turned)\n",
    "    wnd_pts = int(CORR_WND_S * exp.fn)\n",
    "    overlap_pts = wnd_pts // N_OVERLAPS\n",
    "\n",
    "    # Find what ranges are valid, i.e have enough bouts in the interval:\n",
    "    indexes = list(range(0, len(phase) - wnd_pts, overlap_pts))\n",
    "    valid_indexes = []\n",
    "    for i in indexes:\n",
    "        if np.sum(np.abs(theta_turned[i : i + wnd_pts])) > MIN_BOUTS:\n",
    "            valid_indexes.append(i)\n",
    "\n",
    "    shuf_indexes = []\n",
    "    for i in valid_indexes:\n",
    "        shuf_i = i\n",
    "        c = 0\n",
    "        while np.abs(i - shuf_i) < wnd_pts // 2:\n",
    "            shuf_i = np.random.choice(valid_indexes)\n",
    "            c += 1\n",
    "            if c > 50:\n",
    "                print(\"could not find a valid shuffle for \", path.name)\n",
    "                break\n",
    "\n",
    "        shuf_indexes.append(shuf_i)\n",
    "\n",
    "    for i, shuf_i in zip(valid_indexes, shuf_indexes):\n",
    "        wnd = slice(i, i + wnd_pts)\n",
    "        shuf_wnd = slice(shuf_i, shuf_i + wnd_pts)\n",
    "\n",
    "        toshuf = fictive_head[shuf_wnd]\n",
    "\n",
    "        if np.random.rand() > 0.5:\n",
    "            toshuf = -toshuf\n",
    "\n",
    "        rho, _ = spearmanr(phase[wnd], fictive_head[wnd])\n",
    "        rho_shuf, _ = spearmanr(phase[wnd], toshuf)\n",
    "\n",
    "        results_df.append(dict(rho=rho, shuf=rho_shuf, fid=exp.dir_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8af62e-4042-4af1-8ece-85181ff56602",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(results_df)\n",
    "# compute quantiles:\n",
    "quantiles_df = res_df.groupby(\"fid\").quantile((0.25, 0.50, 0.75))\n",
    "\n",
    "# sort on 0.5 quantile:\n",
    "sort_order = quantiles_df.xs(0.5, level=1).sort_values(\"rho\").index\n",
    "\n",
    "# compute p values for each fish:\n",
    "all_p_vals = []\n",
    "for fid in res_df[\"fid\"].unique():\n",
    "    _, p = wilcoxon(*[res_df.loc[res_df[\"fid\"] == fid, k] for k in [\"rho\", \"shuf\"]])\n",
    "    all_p_vals.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4ad76a-8e03-4a89-b89b-0f1808314662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _wilcoxon_p(df, keys=[\"rho\", \"shuf\"]):\n",
    "    _, p = wilcoxon(*[df[k] for k in keys])\n",
    "    return p\n",
    "\n",
    "\n",
    "pvals_df = res_df.groupby(\"fid\").apply(_wilcoxon_p)\n",
    "pvals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2865f873-6001-4b9f-a22d-29f6c6813860",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(3, 2), gridspec_kw=dict(bottom=0.2, left=0.18),)\n",
    "for k, col in zip([\"shuf\", \"rho\"], [COLS[\"shuf\"], COLS[\"ph_plot\"]]):\n",
    "    stacked_quantiles = quantiles_df[[k]].stack().unstack(level=0)\n",
    "    pltltr.tick_with_bars(\n",
    "        stacked_quantiles[sort_order], cols=[col,] * len(sort_order), s=0.2\n",
    "    )\n",
    "\n",
    "\n",
    "# plt.plot(rhos[np.argsort(rhos[:, 1]), :], c=\"r\")\n",
    "ax.set(xlabel=\"Fish n.\", ylabel=\"Correlation (Spearman ρ)\")\n",
    "ax.axhline(0, lw=1, c=\".4\")\n",
    "pltltr.despine(ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e562aff-7215-445c-9d9a-4cc926aed325",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rplab",
   "language": "python",
   "name": "rplab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
