{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "golden-brass",
   "metadata": {},
   "source": [
    "# The aHB circuit tracks fictive trajectories\n",
    "\n",
    "We have seen in the previous notebooks that the aHB integrator could be capabable of keep track of past motion over a significant amount of time. In this notebook, we will see how much it can keep track of past trajectories over significant amounts of time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-whale",
   "metadata": {},
   "source": [
    "## A first look at cumulative directional motion and network phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-connection",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from pathlib import Path\n",
    "\n",
    "import lotr.plotting as pltltr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bouter.utilities import crop\n",
    "from lotr import A_FISH, LotrExperiment, dataset_folders\n",
    "from lotr.behavior import get_bouts_props_array\n",
    "from lotr.default_vals import REGRESSOR_TAU_S\n",
    "from lotr.utils import convolve_with_tau, linear_regression, nan_phase_jumps\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import pearsonr, spearmanr, wilcoxon\n",
    "from tqdm import tqdm\n",
    "\n",
    "from lotr.result_logging import ResultsLogger\n",
    "logger = ResultsLogger()\n",
    "\n",
    "COLS = pltltr.COLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-gibson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, get the unwrapped phase:\n",
    "exp = LotrExperiment(A_FISH)\n",
    "network_phase = np.unwrap(exp.network_phase)\n",
    "\n",
    "# Now, let's find a way of reconstruct past motion of the fish.\n",
    "# We will start with a vector of zeros that has ones at timepoints\n",
    "# where the fish swam:\n",
    "theta_turned = get_bouts_props_array(\n",
    "    exp.n_pts, exp.bouts_df, selection=\"all\", value=\"bias\",\n",
    ")\n",
    "\n",
    "# Fictive heading will be the cumulative sum of this array:\n",
    "fictive_head = np.cumsum(theta_turned)\n",
    "\n",
    "# Finally, we smooth this array with a kernel that matches the slower dynamics\n",
    "# of the neuron (results are not much affected by this)\n",
    "fictive_head = convolve_with_tau(np.cumsum(theta_turned), REGRESSOR_TAU_S * exp.fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-travel",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(\n",
    "    3, 1, figsize=(6., 3), sharex=True, gridspec_kw=(dict(bottom=0.12))\n",
    ")\n",
    "lw = 1\n",
    "\n",
    "labels = [\"Tail angle\", \"Angle turned (dθ)\", \"Fict. heading (θ)\"]\n",
    "col_seq = [COLS[\"beh\"], pltltr.shift_lum(COLS[\"th_plot\"], 0.4), COLS[\"th_plot\"]]\n",
    "for i, (x, y) in enumerate(\n",
    "    [\n",
    "        (exp.behavior_log[\"t\"], exp.behavior_log[\"tail_sum\"]),\n",
    "        (exp.time_arr, theta_turned),\n",
    "        (exp.time_arr, fictive_head),\n",
    "    ]\n",
    "):\n",
    "    axs[i].plot(\n",
    "        x, y, lw=lw, c=col_seq[i], label=labels[i], rasterized=i == 0\n",
    "    )  # rasterize for exporting\n",
    "    axs[i].legend(loc=2, bbox_to_anchor=(0.8, 0.95), labelcolor=\"linecolor\",\n",
    "        handlelength=0.0)\n",
    "\n",
    "axs[0].set(**pltltr.get_pi_labels(1, ax=\"y\"))\n",
    "axs[1].set(**pltltr.get_pi_labels(0.5, ax=\"y\"), ylim=(-1.8, 1.8))\n",
    "axs[2].set(xlabel=\"Time (s)\", **pltltr.get_pi_labels(coefs=(0, -5, -10, -15), ax=\"y\"))\n",
    "\n",
    "[pltltr.despine(ax) for ax in axs.flatten()]\n",
    "plt.show()\n",
    "pltltr.savefig(\"fictive_traj_computation\", folder=\"S7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-financing",
   "metadata": {},
   "source": [
    "Now, how does the network phase look, compared with the fictive heading?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-footwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_off_s, t_dur_s = 150, 400\n",
    "\n",
    "f, ax = plt.subplots(\n",
    "    1, 1, figsize=(4, 1.5), gridspec_kw=(dict(bottom=0.25, right=0.85))\n",
    ")\n",
    "twin_ax = ax.twinx()\n",
    "ax.plot(\n",
    "    exp.time_arr, fictive_head, c=COLS[\"th_plot\"],\n",
    ")\n",
    "twin_ax.plot(\n",
    "    exp.time_arr, np.unwrap(exp.network_phase), c=COLS[\"ph_plot\"],\n",
    ")\n",
    "ax.set_ylabel(\"Fict. heading (θ)\", c=COLS[\"th_plot\"])\n",
    "ax.set(xlabel=\"Times (s)\", **pltltr.get_pi_labels(coefs=(0, -5, -10, -15, -20), ax=\"y\"))\n",
    "twin_ax.set_ylabel(\"Network phase (ϕ)\", c=COLS[\"ph_plot\"])\n",
    "twin_ax.set(**pltltr.get_pi_labels(coefs=(0, 2, 4, 6), ax=\"y\"))\n",
    "ax.set(ylim=(2, -65))\n",
    "# rho, pval = spearmanr(fictive_head, np.unwrap(exp.network_phase))\n",
    "# ax.text(1200, -np.pi, \"$ρ_r=\" + f\"{rho:0.3f}\" + \"$\" + pltltr.get_pval_stars(pval))\n",
    "[pltltr.despine(a, [\"top\"]) for a in [ax, twin_ax]]\n",
    "ax.axvspan(t_off_s, t_off_s + t_dur_s, lw=0, fc=\".9\", zorder=-100)\n",
    "pltltr.savefig(\"fictive_traj_phase_onefish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-turtle",
   "metadata": {},
   "source": [
    "## Quantify correlation over the entire dataset\n",
    "\n",
    "To run the correlation over the entire dataset, we will not use the whole trace to avoid the problem that a large drift at some point of the experiment could disrupt the correlation for the rest of it. Instead, we will use correlation in windows of 5 minutes, including only times where there were at least 2 directional bouts happening (otherwise fictive heading will be a flat line, with which correlation ill-defined)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-victim",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(34897010)\n",
    "\n",
    "CORR_WND_S = 300  # window over which correlation will be computed\n",
    "N_OVERLAPS = 10  # number of overlaps per window\n",
    "MIN_BOUTS = 2  # minimum number of bouts to inclide in the window\n",
    "\n",
    "results_df = []\n",
    "for path in tqdm(dataset_folders):\n",
    "    # for path in tqdm(maybe):\n",
    "    exp = LotrExperiment(path)\n",
    "    phase = np.unwrap(exp.network_phase)\n",
    "    theta_turned = get_bouts_props_array(\n",
    "        exp.n_pts, exp.bouts_df, selection=\"all\", value=\"bias\",\n",
    "    )\n",
    "\n",
    "    # Fictive heading will be the cumulative sum of this array:\n",
    "    fictive_head = np.cumsum(theta_turned)\n",
    "    wnd_pts = int(CORR_WND_S * exp.fn)\n",
    "    overlap_pts = wnd_pts // N_OVERLAPS\n",
    "\n",
    "    # Find what ranges are valid, i.e have enough bouts in the interval:\n",
    "    indexes = list(range(0, len(phase) - wnd_pts, overlap_pts))\n",
    "    valid_indexes = []\n",
    "    for i in indexes:\n",
    "        if np.sum(np.abs(theta_turned[i : i + wnd_pts])) > MIN_BOUTS:\n",
    "            valid_indexes.append(i)\n",
    "\n",
    "    shuf_indexes = []\n",
    "    for i in valid_indexes:\n",
    "        shuf_i = i\n",
    "        c = 0\n",
    "        while np.abs(i - shuf_i) < wnd_pts // 2:\n",
    "            shuf_i = np.random.choice(valid_indexes)\n",
    "            c += 1\n",
    "            if c > 50:\n",
    "                print(\"could not find a valid shuffle for \", path.name)\n",
    "                break\n",
    "\n",
    "        shuf_indexes.append(shuf_i)\n",
    "\n",
    "    for i, shuf_i in zip(valid_indexes, shuf_indexes):\n",
    "        wnd = slice(i, i + wnd_pts)\n",
    "        shuf_wnd = slice(shuf_i, shuf_i + wnd_pts)\n",
    "\n",
    "        toshuf = fictive_head[shuf_wnd]\n",
    "\n",
    "        if np.random.rand() > 0.5:\n",
    "            toshuf = -toshuf\n",
    "\n",
    "        r_corr, _ = pearsonr(\n",
    "            phase[wnd], fictive_head[wnd]\n",
    "        )  # spearmanr(phase[wnd], fictive_head[wnd])\n",
    "        r_shuf, _ = pearsonr(phase[wnd], toshuf)  # spearmanr(phase[wnd], toshuf)\n",
    "\n",
    "        results_df.append(dict(r_corr=r_corr, shuf=r_shuf, fid=exp.dir_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-province",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(results_df)\n",
    "# compute quantiles:\n",
    "quantiles_df = res_df.groupby(\"fid\").quantile((0.25, 0.50, 0.75))\n",
    "\n",
    "# sort on 0.5 quantile:\n",
    "sort_order = quantiles_df.xs(0.5, level=1).sort_values(\"r_corr\").index\n",
    "\n",
    "# compute p values for each fish:\n",
    "def _wilcoxon_p(df, keys=[\"r_corr\", \"shuf\"]):\n",
    "    _, p = wilcoxon(*[df[k] for k in keys])\n",
    "    return p\n",
    "\n",
    "\n",
    "pvals_df = res_df.groupby(\"fid\").apply(_wilcoxon_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-possibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(3, 2), gridspec_kw=dict(bottom=0.2, left=0.18),)\n",
    "for k, lab, col in zip(\n",
    "    [\"shuf\", \"r_corr\"], [\"Shuffle\", \"Data\"], [\".5\", COLS[\"ph_plot\"]]\n",
    "):\n",
    "    stacked_quantiles = quantiles_df[[k]].stack().unstack(level=0)\n",
    "    pltltr.tick_with_bars(\n",
    "        stacked_quantiles[sort_order], cols=[col,] * len(sort_order), s=0.2,\n",
    "    )\n",
    "    # Dummy plot for legend:\n",
    "    plt.plot([np.nan], [np.nan], c=col, label=lab)\n",
    "\n",
    "\n",
    "ax.legend(loc=4, fontsize=7, labelcolor=\"linecolor\",\n",
    "        handlelength=0.0)\n",
    "# plt.plot(rhos[np.argsort(rhos[:, 1]), :], c=\"r\")\n",
    "ax.set(xlabel=\"Fish (sorted by corr.)\", ylabel=\"Heading/phase corr.\")\n",
    "ax.axhline(0, lw=1, c=\".4\")\n",
    "pltltr.despine(ax)\n",
    "plt.show()\n",
    "\n",
    "pltltr.savefig(\"correlations_all_fish_nostats\")\n",
    "y_txt = 0.7\n",
    "for i, pval in enumerate(pvals_df[sort_order]):\n",
    "    plt.text(\n",
    "        i,\n",
    "        y_txt,\n",
    "        pltltr.get_pval_stars(pval),\n",
    "        fontsize=6,\n",
    "        rotation=\"vertical\",\n",
    "        zorder=100,\n",
    "        va=\"top\",\n",
    "    )\n",
    "\n",
    "pltltr.savefig(\"correlations_all_fish_stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce380085-3140-4713-86ce-28af8dd2e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(1.5, 2.5), gridspec_kw=(dict(bottom=0.2, left=0.4)))\n",
    "ax.scatter(np.ones(len(pvals_df)) + np.random.rand(len(pvals_df))*0.4, -np.log10(pvals_df), s=10)\n",
    "ax.set(xlim=(0, 2), ylabel=\"-log10(p_val)\", ylim=(0.5, 11))\n",
    "ax.axhline(-np.log10(0.05), lw=0.5, c=\".6\")\n",
    "pltltr.despine(ax, [\"bottom\", \"right\", \"top\"])\n",
    "pltltr.savefig(\"pvals_distr\", folder=\"S7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba19aa92-fd5d-468c-bd42-fcc5ad1779e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_quantiles = quantiles_df[[\"r_corr\"]].stack().unstack(level=0)\n",
    "logger.add_entry(\"heading_phase_corr\", stacked_quantiles.xs((0.5, \"r_corr\")), stacked_quantiles.xs((0.5, \"r_corr\")).index, moment=\"median\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dae7137-24c9-4fe4-84a4-ee606e5048e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.add_entry(\"pvals_corrs\", pvals_df, stacked_quantiles.xs((0.5, \"r_corr\")).index, moment=\"minmax\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bf8faa-7770-43f6-affa-808613ed3e90",
   "metadata": {},
   "source": [
    "### Traces for all fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306d1772-8248-4813-8fd3-d997b12beeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(11, 3, figsize=(8, 8), gridspec_kw=dict(wspace=0.35, hspace=0.4))\n",
    "\n",
    "axs_flat = axs.flatten()\n",
    "results_df = []\n",
    "for i, path in tqdm(enumerate(dataset_folders)):\n",
    "    # for path in tqdm(maybe):\n",
    "    exp = LotrExperiment(path)\n",
    "    phase = np.unwrap(exp.network_phase)\n",
    "    theta_turned = get_bouts_props_array(\n",
    "        exp.n_pts, exp.bouts_df, selection=\"all\", value=\"bias\",\n",
    "    )\n",
    "    fictive_head = np.cumsum(theta_turned)\n",
    "\n",
    "    ax = axs_flat[i]\n",
    "    \n",
    "    twin_ax = ax.twinx()\n",
    "    ax.plot(\n",
    "        exp.time_arr, fictive_head, c=COLS[\"th_plot\"], label=\"Estimated heading\"\n",
    "    )\n",
    "    ax.plot([], [], c=COLS[\"ph_plot\"], label=\"Network phase\"\n",
    "    )\n",
    "    twin_ax.plot(\n",
    "        exp.time_arr, np.unwrap(exp.network_phase), c=COLS[\"ph_plot\"],\n",
    "    )\n",
    "    ax.set_title(path.name, fontsize=6, ha=\"right\")\n",
    "    lims = twin_ax.get_ylim()\n",
    "    twin_ax.set_ylim((lims[1], lims[0]))\n",
    "    pltltr.add_scalebar(ax, xlen=500, ylen=0, disable_axis=False, xlabel=\"\", ylabel=\"\")\n",
    "\n",
    "    [pltltr.despine(a, [\"top\", \"bottom\"]) for a in [ax, twin_ax]]\n",
    "    for a, col in zip([ax, twin_ax], [COLS[\"th_plot\"], COLS[\"ph_plot\"]]):\n",
    "        [t.set_color(col) for t in a.yaxis.get_ticklines()]\n",
    "        [t.set_color(col) for t in a.yaxis.get_ticklabels()]\n",
    "# ax.axvspan(t_off_s, t_off_s + t_dur_s, lw=0, fc=\".9\", zorder=-100)\n",
    "\n",
    "[pltltr.despine(axs_flat[j], \"all\") for j in range(i+1, len(axs_flat))]\n",
    "    \n",
    "\n",
    "axs[0, -1].legend(loc=2, bbox_to_anchor=(0.55, 2), labelcolor=\"linecolor\",\n",
    "        handlelength=0.0)\n",
    "\n",
    "pltltr.savefig(\"phase_heading_allfish\", folder=\"S7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4cbbca-5fc1-4b75-a8df-ee4791d40237",
   "metadata": {},
   "outputs": [],
   "source": [
    "axs[0, -1].legend(loc=2, bbox_to_anchor=(0.4, 2), labelcolor=\"linecolor\", ha=\"right\",\n",
    "        handlelength=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769fee1d-b349-4f86-8a42-3d4fe2344c81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lotr",
   "language": "python",
   "name": "lotr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
